#!/usr/bin/env python3
"""
ç›´æ¥ä½¿ç”¨ OpenAI Python åº“çš„æµ‹è¯•ä»£ç 
"""

import os
from openai import OpenAI


def test_openai_with_base_url(base_url=None, stream=False):
    """ä½¿ç”¨è‡ªå®šä¹‰ base_url æµ‹è¯• OpenAI APIï¼ˆç”¨äºæµ‹è¯•ä»£ç†ï¼‰"""
    
    client = OpenAI(api_key=openai_api_key, base_url=base_url)
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "Hello! This is a test through proxy."}
            ],
            max_tokens=50,
            temperature=0.7,
            stream=stream,
        )
        
        if stream:
            print("ğŸ“¡ æµå¼å“åº”:", end=" ")
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    print(chunk.choices[0].delta.content, end="")
            print(f"\nâœ… æµå¼å“åº”æµ‹è¯•å®Œæˆ (base_url: {base_url})")
        else:
            print(f"âœ… OpenAI é€šè¿‡ä»£ç†è°ƒç”¨æˆåŠŸ (base_url: {base_url})")
            print(f"å›å¤: {response.choices[0].message.content}")
        
    except Exception as e:
        print(f"âŒ OpenAI ä»£ç†è°ƒç”¨å¤±è´¥: {e}") 

openai_api_key = os.getenv("OPENAI_API_KEY")
openai_base_url = "http://localhost:8080/openai/v1"

def main():
    
    test_openai_with_base_url()
    test_openai_with_base_url(openai_base_url)
    test_openai_with_base_url(openai_base_url, stream=True)


if __name__ == "__main__":
    main()